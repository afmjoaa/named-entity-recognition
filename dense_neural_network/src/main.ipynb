{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pre_process import PreProcess\n",
    "from word_to_vector import WordToVector\n",
    "from one_hot_encoding import OneHotEncoder\n",
    "import numpy as np\n",
    "from training import DnnTraining\n",
    "from inference import DnnInference\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "186433 53266 26635\n",
      "186433 53266 26635\n"
     ]
    }
   ],
   "source": [
    "word_arr_one, label_arr_one = PreProcess.getTrainingTuple(dataFile='../../data/en-train.conll', onlyBioTagging=True)\n",
    "word_arr_two, label_arr_two = PreProcess.getTrainingTuple(dataFile='../../data/en-dev.conll', onlyBioTagging=True)\n",
    "\n",
    "word_arr = word_arr_one + word_arr_two\n",
    "label_arr = label_arr_one + label_arr_two\n",
    "\n",
    "n = len(word_arr)\n",
    "train_split = int(0.7 * n)\n",
    "val_split = int(0.2 * n)\n",
    "train_word_arr = word_arr[:train_split]\n",
    "val_word_arr = word_arr[train_split:train_split + val_split]\n",
    "test_word_arr = word_arr[train_split + val_split:]\n",
    "print(len(train_word_arr), len(val_word_arr), len(test_word_arr))\n",
    "\n",
    "m = len(label_arr)\n",
    "train_label_split = int(0.7 * m)\n",
    "val_label_split = int(0.2 * m)\n",
    "train_label_arr = label_arr[:train_label_split]\n",
    "val_label_arr = label_arr[train_label_split:train_label_split + val_label_split]\n",
    "test_label_arr = label_arr[train_label_split + val_label_split:]\n",
    "print(len(train_label_arr), len(val_label_arr), len(test_label_arr))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def pipelineTest(train_word_arr, train_label_arr, val_word_arr, val_label_arr):\n",
    "    # Get wordToVector from [wordArr] and oneHotEncoding from [labelArr]\n",
    "    wordToVecArr = WordToVector.getPretrainedWordToVecList(train_word_arr)\n",
    "    oneHotEncodingArr = OneHotEncoder.getOneHotEncodingOfOutput(train_label_arr)\n",
    "    # Convert python array to num py array\n",
    "    np_wordToVecArr = np.array(wordToVecArr)\n",
    "    np_oneHotEncodingArr = np.array(oneHotEncodingArr)\n",
    "\n",
    "    # Get wordToVector from [wordArr] and oneHotEncoding from [labelArr]\n",
    "    val_wordToVecArr = WordToVector.getPretrainedWordToVecList(val_word_arr)\n",
    "    val_oneHotEncodingArr = OneHotEncoder.getOneHotEncodingOfOutput(val_label_arr)\n",
    "    # Convert python array to num py array\n",
    "    val_np_wordToVecArr = np.array(val_wordToVecArr)\n",
    "    val_np_oneHotEncodingArr = np.array(val_oneHotEncodingArr)\n",
    "\n",
    "    training = DnnTraining(input_dim=300, output_dim=3)\n",
    "    training.startTraining(np_wordToVecArr, np_oneHotEncodingArr, val_np_wordToVecArr, val_np_oneHotEncodingArr, epochs=100)\n",
    "    training.saveTrainedModel()\n",
    "\n",
    "pipelineTest(train_word_arr, train_label_arr, val_word_arr, val_label_arr)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def predict(test_data, test_label):\n",
    "    model = load_model('dnn_model.h5')\n",
    "    inference = DnnInference(test_data, test_label)\n",
    "    inference.inferenceAndPrint(model, 20)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
